import requests
from bs4 import BeautifulSoup

def scrape_textareas(url):
    """ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å <textarea> ‡πÉ‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° """
    try:
        # ‡∏™‡πà‡∏á HTTP GET request ‡πÑ‡∏õ‡∏¢‡∏±‡∏á URL
        response = requests.get(url)
        response.raise_for_status()  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î HTTP

        # ‡πÉ‡∏ä‡πâ BeautifulSoup ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå HTML
        soup = BeautifulSoup(response.text, 'html.parser')

        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ <textarea> ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
        textareas = soup.find_all('textarea')

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏ï‡πà‡∏•‡∏∞ <textarea> ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏•‡∏¥‡∏™‡∏ï‡πå
        return [textarea.get_text().strip() for textarea in textareas]

    except requests.exceptions.RequestException as e:
        print(f'‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}')
        return []

# üîπ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
url = 'https://elabsheet.org/elab/taskpads/workon/7hoqhluyq2/uqn2mfcu37/'
textarea_data = scrape_textareas(url)

# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡πÑ‡∏î‡πâ
for i, data in enumerate(textarea_data, start=1):
    print(f'Textarea #{i}:')
    print(data)
    print('-' * 40)

